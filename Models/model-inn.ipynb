{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e066db",
   "metadata": {},
   "source": [
    "# Dataset importing and refining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4f1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports for data processing and model training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ea287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   69    1   0       160   234    1        2      131      0      0.1      1   \n",
      "1   69    0   0       140   239    0        0      151      0      1.8      0   \n",
      "2   66    0   0       150   226    0        0      114      0      2.6      2   \n",
      "3   65    1   0       138   282    1        2      174      0      1.4      1   \n",
      "4   64    1   0       110   211    0        2      144      1      1.8      1   \n",
      "\n",
      "   ca  thal  condition  \n",
      "0   1     0          0  \n",
      "1   2     0          0  \n",
      "2   0     0          0  \n",
      "3   1     0          1  \n",
      "4   0     0          0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 297 entries, 0 to 296\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        297 non-null    int64  \n",
      " 1   sex        297 non-null    int64  \n",
      " 2   cp         297 non-null    int64  \n",
      " 3   trestbps   297 non-null    int64  \n",
      " 4   chol       297 non-null    int64  \n",
      " 5   fbs        297 non-null    int64  \n",
      " 6   restecg    297 non-null    int64  \n",
      " 7   thalach    297 non-null    int64  \n",
      " 8   exang      297 non-null    int64  \n",
      " 9   oldpeak    297 non-null    float64\n",
      " 10  slope      297 non-null    int64  \n",
      " 11  ca         297 non-null    int64  \n",
      " 12  thal       297 non-null    int64  \n",
      " 13  condition  297 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 32.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '/media/jeyanth-s/DevDrive/AI_Workspace/projects/Heart Disease Project Repository/Heart-Disease-Prediction---Cognitives/Datasets/dataset3.csv'\n",
    "# Load dataset (example CSV)\n",
    "data = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# Quick overview\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d811dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (297, 28)\n"
     ]
    }
   ],
   "source": [
    "# Separate target column\n",
    "target = data['condition'].values\n",
    "data = data.drop(columns=['condition'])\n",
    "\n",
    "# Define numerical and categorical columns based on your dataset\n",
    "num_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "cat_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "# Extract numerical and categorical data\n",
    "data_num = data[num_features].copy()\n",
    "data_cat = data[cat_features].copy()\n",
    "\n",
    "# Normalize numerical features (MinMaxScaler to [0,1])\n",
    "scaler = MinMaxScaler()\n",
    "data_num_scaled = scaler.fit_transform(data_num)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "data_cat_encoded = encoder.fit_transform(data_cat)\n",
    "\n",
    "# Combine numerical and categorical data\n",
    "data_processed = np.hstack((data_num_scaled, data_cat_encoded))\n",
    "\n",
    "print(\"Processed data shape:\", data_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2517c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_missingness(data, missing_rate=0.1):\n",
    "    data_missing = data.copy()\n",
    "    n_samples, n_features = data.shape\n",
    "    \n",
    "    # Calculate total number of values to mask\n",
    "    n_missing = int(np.floor(missing_rate * n_samples * n_features))\n",
    "    \n",
    "    # Randomly select indices to mask\n",
    "    missing_indices = (\n",
    "        np.random.randint(0, n_samples, n_missing),\n",
    "        np.random.randint(0, n_features, n_missing)\n",
    "    )\n",
    "    \n",
    "    data_missing[missing_indices] = np.nan\n",
    "    return data_missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da29cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values introduced: 794\n",
      "[[0.83333333 0.62264151 0.24657534 0.45801527 0.01612903 0.\n",
      "  1.         1.         0.         0.         0.         0.\n",
      "  1.         0.         0.         1.         1.                nan\n",
      "  0.         1.         0.         0.         1.         0.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.83333333 0.43396226 0.25799087 0.61068702 0.29032258 1.\n",
      "  0.         1.                nan 0.         0.         1.\n",
      "  0.         1.         0.                nan 1.         0.\n",
      "  1.         0.         0.         0.         0.         1.\n",
      "  0.         1.         0.                nan]\n",
      " [0.77083333 0.52830189 0.2283105  0.32824427 0.41935484 1.\n",
      "  0.         1.         0.         0.         0.         1.\n",
      "  0.         1.         0.         0.         1.         0.\n",
      "  0.         0.         1.         1.         0.         0.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.75       0.41509434 0.35616438 0.78625954 0.22580645 0.\n",
      "  1.         1.         0.         0.         0.         0.\n",
      "  1.         0.         0.         1.         1.         0.\n",
      "         nan 1.         0.         0.         1.         0.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.72916667 0.1509434  0.19406393 0.55725191 0.29032258        nan\n",
      "  1.         1.         0.         0.         0.         1.\n",
      "  0.         0.         0.         1.         0.                nan\n",
      "  0.         1.         0.         1.         0.         0.\n",
      "  0.         1.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Introduce 10% missing values\n",
    "data_with_missing = introduce_missingness(data_processed, missing_rate=0.1)\n",
    "\n",
    "# Check how many missing values were introduced\n",
    "print(\"Number of missing values introduced:\", np.isnan(data_with_missing).sum())\n",
    "\n",
    "# Preview some rows with missing values\n",
    "print(data_with_missing[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33482b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation: 0\n",
      "[[0.83333333 0.62264151 0.24657534 0.45801527 0.01612903 0.\n",
      "  1.         1.         0.         0.         0.         0.\n",
      "  1.         0.         0.         1.         1.         0.2\n",
      "  0.         1.         0.         0.         1.         0.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.83333333 0.43396226 0.25799087 0.61068702 0.29032258 1.\n",
      "  0.         1.         0.4        0.         0.         1.\n",
      "  0.         1.         0.         0.         1.         0.\n",
      "  1.         0.         0.         0.         0.         1.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.77083333 0.52830189 0.2283105  0.32824427 0.41935484 1.\n",
      "  0.         1.         0.         0.         0.         1.\n",
      "  0.         1.         0.         0.         1.         0.\n",
      "  0.         0.         1.         1.         0.         0.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.75       0.41509434 0.35616438 0.78625954 0.22580645 0.\n",
      "  1.         1.         0.         0.         0.         0.\n",
      "  1.         0.         0.         1.         1.         0.\n",
      "  0.2        1.         0.         0.         1.         0.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.72916667 0.1509434  0.19406393 0.55725191 0.29032258 0.2\n",
      "  1.         1.         0.         0.         0.         1.\n",
      "  0.         0.         0.         1.         0.         0.4\n",
      "  0.         1.         0.         1.         0.         0.\n",
      "  0.         1.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def knn_impute(data_missing, k=5):\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    data_imputed = imputer.fit_transform(data_missing)\n",
    "    return data_imputed\n",
    "\n",
    "# Example: impute with k=5\n",
    "data_imputed = knn_impute(data_with_missing, k=5)\n",
    "\n",
    "# Check that no missing values remain\n",
    "print(\"Missing values after imputation:\", np.isnan(data_imputed).sum())\n",
    "\n",
    "# Preview imputed data\n",
    "print(data_imputed[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01927425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "INAAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=28, out_features=14, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=28, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/jeyanth-s/DevDrive/AI_Workspace/envs/pytorch-env/lib/python3.12/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class INAAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(INAAutoencoder, self).__init__()\n",
    "        hidden_dim = input_dim // 2  # undercomplete architecture\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # To constrain outputs between 0 and 1 (since input is normalized)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Initialize model\n",
    "input_dim = data_processed.shape[1]\n",
    "model = INAAutoencoder(input_dim).to(device)\n",
    "\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
