{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19ca6d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from C:\\Users\\ashraf deen\\OneDrive\\Desktop\\Heart Disease\\Heart-Disease-Prediction---Cognitives\\Datasets\\dataset4.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           70000 non-null  int64  \n",
      " 1   age          70000 non-null  int64  \n",
      " 2   gender       70000 non-null  int64  \n",
      " 3   height       70000 non-null  int64  \n",
      " 4   weight       70000 non-null  float64\n",
      " 5   ap_hi        70000 non-null  int64  \n",
      " 6   ap_lo        70000 non-null  int64  \n",
      " 7   cholesterol  70000 non-null  int64  \n",
      " 8   gluc         70000 non-null  int64  \n",
      " 9   smoke        70000 non-null  int64  \n",
      " 10  alco         70000 non-null  int64  \n",
      " 11  active       70000 non-null  int64  \n",
      " 12  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(12)\n",
      "memory usage: 6.9 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "age            0\n",
       "gender         0\n",
       "height         0\n",
       "weight         0\n",
       "ap_hi          0\n",
       "ap_lo          0\n",
       "cholesterol    0\n",
       "gluc           0\n",
       "smoke          0\n",
       "alco           0\n",
       "active         0\n",
       "cardio         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential categorical features:\n",
      "['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
      "\n",
      "Potential numerical features:\n",
      "['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
      "\n",
      "Potential Preprocessing Steps:\n",
      "For categorical features (gender, cholesterol, gluc, smoke, alco, active, cardio):\n",
      "- One-Hot Encoding or Label Encoding depending on the nature of the feature and the model.\n",
      "- Handling potential inconsistencies in categorical values if any are discovered.\n",
      "For numerical features (age, height, weight, ap_hi, ap_lo):\n",
      "- Scaling (e.g., StandardScaler or MinMaxScaler) to bring features to a similar range.\n",
      "- Handling outliers in features like 'ap_hi' and 'ap_lo' (blood pressure) which can have physiologically impossible values.\n",
      "- Checking for and addressing potential data entry errors or inconsistencies.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\ashraf deen\\OneDrive\\Desktop\\Heart Disease\\Heart-Disease-Prediction---Cognitives\\Datasets\\dataset4.csv\"\n",
    "\n",
    "try:\n",
    "    # Read the CSV file using semicolon as a separator and specify the column names\n",
    "    # Explicitly define column names based on the task description\n",
    "    column_names = ['id', 'age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "    df = pd.read_csv(file_path, sep=';', names=column_names, header=0) # Assuming the first row is a header\n",
    "\n",
    "    print(f\"Successfully loaded data from {file_path}\")\n",
    "    # Display the first few rows\n",
    "    display(df.head())\n",
    "    # Print the data types of each column\n",
    "    display(df.info())\n",
    "    # Check for and report any missing values\n",
    "    display(df.isnull().sum())\n",
    "\n",
    "    # Identify categorical features (assuming non-numeric types or specific integer codes)\n",
    "    # Based on the initial task description and common understanding of such datasets\n",
    "    categorical_features = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "    print(\"\\nPotential categorical features:\")\n",
    "    print(categorical_features)\n",
    "\n",
    "    # Identify numerical features (assuming numeric types excluding identified categorical and 'id')\n",
    "    numerical_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "    print(\"\\nPotential numerical features:\")\n",
    "    print(numerical_features)\n",
    "\n",
    "    # Discuss potential preprocessing steps\n",
    "    print(\"\\nPotential Preprocessing Steps:\")\n",
    "    print(\"For categorical features (gender, cholesterol, gluc, smoke, alco, active, cardio):\")\n",
    "    print(\"- One-Hot Encoding or Label Encoding depending on the nature of the feature and the model.\")\n",
    "    print(\"- Handling potential inconsistencies in categorical values if any are discovered.\")\n",
    "    print(\"For numerical features (age, height, weight, ap_hi, ap_lo):\")\n",
    "    print(\"- Scaling (e.g., StandardScaler or MinMaxScaler) to bring features to a similar range.\")\n",
    "    print(\"- Handling outliers in features like 'ap_hi' and 'ap_lo' (blood pressure) which can have physiologically impossible values.\")\n",
    "    print(\"- Checking for and addressing potential data entry errors or inconsistencies.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please ensure the file is in the correct directory.\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during file loading: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b600f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values...\n",
      "id             0\n",
      "age            0\n",
      "gender         0\n",
      "height         0\n",
      "weight         0\n",
      "ap_hi          0\n",
      "ap_lo          0\n",
      "cholesterol    0\n",
      "gluc           0\n",
      "smoke          0\n",
      "alco           0\n",
      "active         0\n",
      "cardio         0\n",
      "dtype: int64\n",
      "\n",
      "No missing values found.\n",
      "\n",
      "Shape of the processed data:\n",
      "(70000, 22)\n",
      "\n",
      "First 5 rows of the processed data (numpy array):\n",
      "[[-0.43606151  0.44345206 -0.84787326 -0.12218198 -0.0882385   0.\n",
      "   1.          1.          0.          0.          1.          0.\n",
      "   0.          1.          0.          1.          0.          0.\n",
      "   1.          1.          0.          0.        ]\n",
      " [ 0.30768633 -1.01816804  0.74983117  0.07261016 -0.03517999  1.\n",
      "   0.          0.          0.          1.          1.          0.\n",
      "   0.          1.          0.          1.          0.          0.\n",
      "   1.          0.          1.          1.        ]\n",
      " [-0.24799666  0.07804703 -0.70894244  0.00767945 -0.14129701  1.\n",
      "   0.          0.          0.          1.          1.          0.\n",
      "   0.          1.          0.          1.          0.          1.\n",
      "   0.          0.          1.          2.        ]\n",
      " [-0.74815189  0.56525373  0.54143494  0.13754088  0.01787852  0.\n",
      "   1.          1.          0.          0.          1.          0.\n",
      "   0.          1.          0.          1.          0.          0.\n",
      "   1.          0.          1.          3.        ]\n",
      " [-0.8085434  -1.01816804 -1.26466572 -0.18711269 -0.19435552  1.\n",
      "   0.          1.          0.          0.          1.          0.\n",
      "   0.          1.          0.          1.          0.          1.\n",
      "   0.          1.          0.          4.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Checking for missing values...\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\nHandling missing values...\")\n",
    "    # Example: Fill missing numerical values with the mean\n",
    "    for col in numerical_features:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "    # Example: Fill missing categorical values with the mode\n",
    "    for col in categorical_features:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    print(\"Missing values handled.\")\n",
    "else:\n",
    "    print(\"\\nNo missing values found.\")\n",
    "\n",
    "\n",
    "# Define transformers for numerical and categorical features\n",
    "# Exclude 'id' from numerical features for scaling\n",
    "# Ensure that the columns exist in the dataframe before adding them to the lists\n",
    "numerical_features_for_scaling = [col for col in numerical_features if col != 'id' and col in df.columns]\n",
    "categorical_features_in_df = [col for col in categorical_features if col in df.columns]\n",
    "\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformations to different columns\n",
    "# 'id' column is passed through as it's not needed for scaling or encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features_for_scaling),\n",
    "        ('cat', categorical_transformer, categorical_features_in_df)],\n",
    "    remainder='passthrough') # Keep the 'id' column\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocess_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Apply preprocessing\n",
    "df_processed = preprocess_pipeline.fit_transform(df)\n",
    "\n",
    "# Display the shape of the processed data\n",
    "print(\"\\nShape of the processed data:\")\n",
    "print(df_processed.shape)\n",
    "\n",
    "# Display a few rows of the processed data (Note: This will be a numpy array after one-hot encoding)\n",
    "print(\"\\nFirst 5 rows of the processed data (numpy array):\")\n",
    "print(df_processed[:5])\n",
    "\n",
    "# You can get the feature names after one-hot encoding if needed for later steps\n",
    "# This requires fitting the OneHotEncoder separately or accessing it from the fitted pipeline\n",
    "# For now, we'll just display the processed numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66d406ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prompt generated from the first row of the dataset:\n",
      "Based on the following health data, provide a health summary and advice:\n",
      "\n",
      "age: 18393.0\n",
      "gender: 2.0\n",
      "height: 168.0\n",
      "weight: 62.0\n",
      "ap_hi: 110.0\n",
      "ap_lo: 80.0\n",
      "cholesterol: 1.0\n",
      "gluc: 1.0\n",
      "smoke: 0.0\n",
      "alco: 0.0\n",
      "active: 1.0\n",
      "cardio: 0.0\n",
      "\n",
      "Provide a summary of potential health risks based on this data, focusing on cardiovascular health. Then, offer actionable advice to maintain or improve health, considering the provided attributes.Keep the summary concise and the advice practical.\n"
     ]
    }
   ],
   "source": [
    "# This code block focuses on preparing data for prompting a generative model.\n",
    "# Actual LLM interaction will be in subsequent steps.\n",
    "\n",
    "# Display the processed data (if you want to see how it looks before using it for prompts)\n",
    "# print(\"\\nProcessed Data (first 5 rows):\")\n",
    "# print(df_processed[:5])\n",
    "\n",
    "# Example of how you might structure data from your dataset to create prompts.\n",
    "# This is a conceptual example and will need to be adapted based on the specific LLM API used\n",
    "# and the desired format of the input and output.\n",
    "\n",
    "# Let's assume we want to create prompts that provide health advice based on a user's\n",
    "# health attributes, using examples from the dataset to guide the LLM.\n",
    "\n",
    "# First, let's look at the original DataFrame again to understand the structure\n",
    "# display(df.head())\n",
    "\n",
    "# We can create prompt examples by pairing health attributes with the 'cardio' outcome\n",
    "# and potentially deriving some simple advice based on the attributes.\n",
    "\n",
    "def create_health_summary_advice_prompt(health_data):\n",
    "    \"\"\"\n",
    "    Creates a prompt for an LLM to generate a health summary and advice\n",
    "    based on provided health data.\n",
    "\n",
    "    Args:\n",
    "        health_data (dict): A dictionary containing the user's health attributes.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted prompt string.\n",
    "    \"\"\"\n",
    "    prompt = \"Based on the following health data, provide a health summary and advice:\\n\\n\"\n",
    "    for key, value in health_data.items():\n",
    "        prompt += f\"{key}: {value}\\n\"\n",
    "\n",
    "    # Add context or instructions for the LLM\n",
    "    prompt += \"\\nProvide a summary of potential health risks based on this data, focusing on cardiovascular health. Then, offer actionable advice to maintain or improve health, considering the provided attributes.\"\n",
    "    prompt += \"Keep the summary concise and the advice practical.\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# Example of creating a prompt for the first individual in the dataset\n",
    "# (assuming df is your loaded pandas DataFrame)\n",
    "if df is not None and not df.empty:\n",
    "    first_individual_data = df.iloc[0].drop('id').to_dict() # Exclude 'id' for the prompt\n",
    "    example_prompt = create_health_summary_advice_prompt(first_individual_data)\n",
    "    print(\"\\nExample Prompt generated from the first row of the dataset:\")\n",
    "    print(example_prompt)\n",
    "\n",
    "    # In a real application, you would then send this prompt to an LLM API.\n",
    "    # We will cover the LLM interaction in a subsequent step.\n",
    "\n",
    "else:\n",
    "    print(\"\\nDataFrame is not loaded or is empty. Cannot generate example prompt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93e67635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing available models:\n",
      "Name: models/embedding-gecko-001, Supported Generation Methods: ['embedText', 'countTextTokens']\n",
      "Name: models/gemini-1.5-pro-latest, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemini-1.5-pro-002, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Name: models/gemini-1.5-pro, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemini-1.5-flash-latest, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemini-1.5-flash, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemini-1.5-flash-002, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Name: models/gemini-1.5-flash-8b, Supported Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Name: models/gemini-1.5-flash-8b-001, Supported Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Name: models/gemini-1.5-flash-8b-latest, Supported Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Name: models/gemini-2.5-pro-preview-03-25, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.5-flash-preview-05-20, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.5-flash, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.5-flash-lite-preview-06-17, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.5-pro-preview-05-06, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.5-pro-preview-06-05, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.5-pro, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-exp, Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Name: models/gemini-2.0-flash, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-001, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-exp-image-generation, Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Name: models/gemini-2.0-flash-lite-001, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-lite, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-preview-image-generation, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemini-2.0-flash-lite-preview-02-05, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-lite-preview, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-pro-exp, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-pro-exp-02-05, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-exp-1206, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-thinking-exp-01-21, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-thinking-exp, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.0-flash-thinking-exp-1219, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/gemini-2.5-flash-preview-tts, Supported Generation Methods: ['countTokens', 'generateContent']\n",
      "Name: models/gemini-2.5-pro-preview-tts, Supported Generation Methods: ['countTokens', 'generateContent']\n",
      "Name: models/learnlm-2.0-flash-experimental, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemma-3-1b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemma-3-4b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemma-3-12b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemma-3-27b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemma-3n-e4b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemma-3n-e2b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "Name: models/gemini-2.5-flash-lite, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "Name: models/embedding-001, Supported Generation Methods: ['embedContent']\n",
      "Name: models/text-embedding-004, Supported Generation Methods: ['embedContent']\n",
      "Name: models/gemini-embedding-exp-03-07, Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens']\n",
      "Name: models/gemini-embedding-exp, Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens']\n",
      "Name: models/gemini-embedding-001, Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens']\n",
      "Name: models/aqa, Supported Generation Methods: ['generateAnswer']\n",
      "Name: models/imagen-3.0-generate-002, Supported Generation Methods: ['predict']\n",
      "Name: models/imagen-4.0-generate-preview-06-06, Supported Generation Methods: ['predict']\n",
      "Name: models/imagen-4.0-ultra-generate-preview-06-06, Supported Generation Methods: ['predict']\n",
      "Name: models/veo-2.0-generate-001, Supported Generation Methods: ['predictLongRunning']\n",
      "Name: models/veo-3.0-generate-preview, Supported Generation Methods: ['predictLongRunning']\n",
      "Name: models/veo-3.0-fast-generate-preview, Supported Generation Methods: ['predictLongRunning']\n",
      "Name: models/gemini-2.5-flash-preview-native-audio-dialog, Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n",
      "Name: models/gemini-2.5-flash-exp-native-audio-thinking-dialog, Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n",
      "Name: models/gemini-2.0-flash-live-001, Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n",
      "Name: models/gemini-live-2.5-flash-preview, Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n",
      "Name: models/gemini-2.5-flash-live-preview, Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n",
      "Generative Model initialized.\n",
      "\n",
      "Generating health summary and advice for the first individual in the dataset...\n",
      "\n",
      "--- Health Summary and Advice ---\n",
      "**Health Summary:**\n",
      "\n",
      "The provided age (18393 days, approximately 50 years) is a significant risk factor.  While blood pressure (110/80), cholesterol, glucose, and smoking/alcohol history are currently within acceptable ranges, age increases the likelihood of developing cardiovascular disease.  The individual is active, which is a positive factor.  The absence of a cardiovascular disease diagnosis at present doesn't eliminate future risk.\n",
      "\n",
      "**Health Advice:**\n",
      "\n",
      "* **Schedule a Comprehensive Check-up:**  Given the age, a thorough physical exam including blood work (lipids, glucose, etc.) and potentially an EKG is recommended to establish a baseline and screen for any early indicators of cardiovascular issues.\n",
      "* **Maintain Healthy Lifestyle:** Continue being physically active. Aim for at least 150 minutes of moderate-intensity or 75 minutes of vigorous-intensity aerobic activity per week, along with muscle-strengthening activities twice a week.\n",
      "* **Dietary Focus:** Maintain a balanced diet rich in fruits, vegetables, whole grains, and lean proteins. Limit saturated and trans fats, sodium, and added sugars.\n",
      "* **Monitor Blood Pressure:** Regularly monitor blood pressure.  Even though it's currently normal, regular checks are important as it can fluctuate.\n",
      "* **Stress Management:** Incorporate stress-reducing techniques like yoga, meditation, or spending time in nature, as chronic stress can negatively impact cardiovascular health.\n",
      "* **Regular Health Screenings:**  Schedule routine checkups and screenings as recommended by your physician, including blood pressure and cholesterol checks.\n",
      "\n",
      "**Important Note:** This advice is based on the limited data provided. It is not a substitute for professional medical advice.  A healthcare provider can provide a more personalized assessment and recommendations based on a complete medical history and physical examination.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for interacting with the LLM\n",
    "# This example uses Google's Generative AI library.\n",
    "# You might need to install it: !pip install google-generativeai\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "# from google.colab import userdata\n",
    "genai.configure(api_key=\"AIzaSyBzlOQ7y7n0z-P6WcEwPV8wDIb3oeKsMPI\")\n",
    "# --- LLM Setup ---\n",
    "# Configure the API key\n",
    "# try:\n",
    "#     # Access the API key from Colab's secrets manager\n",
    "#     GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "#     genai.configure(api_key=GOOGLE_API_KEY)\n",
    "# except userdata.SecretNotFoundError:\n",
    "#     print(\"API key not found. Please store your Google API key in Colab's secrets manager with the name 'GOOGLE_API_KEY'.\")\n",
    "#     genai = None # Set genai to None if API key is not found\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred during API key configuration: {e}\")\n",
    "#     genai = None\n",
    "\n",
    "# List available models\n",
    "if genai is not None:\n",
    "    print(\"Listing available models:\")\n",
    "    try:\n",
    "        for m in genai.list_models():\n",
    "            print(f\"Name: {m.name}, Supported Generation Methods: {m.supported_generation_methods}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while listing models: {e}\")\n",
    "\n",
    "# Initialize the Generative Model\n",
    "if genai is not None:\n",
    "    try:\n",
    "        # Use a suitable model that supports 'generateContent'\n",
    "        # Updated model name to 'gemini-1.5-flash-latest'\n",
    "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "        print(\"Generative Model initialized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during model initialization: {e}\")\n",
    "        gemini_model = None\n",
    "else:\n",
    "    gemini_model = None\n",
    "\n",
    "\n",
    "# --- Summarizer and Advisor Function ---\n",
    "def get_health_summary_and_advice(health_data):\n",
    "    \"\"\"\n",
    "    Generates a health summary and advice using an LLM based on provided health data.\n",
    "\n",
    "    Args:\n",
    "        health_data (dict): A dictionary containing the user's health attributes.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated health summary and advice, or an error message.\n",
    "    \"\"\"\n",
    "    if gemini_model is None:\n",
    "        return \"LLM is not initialized. Cannot generate summary and advice.\"\n",
    "\n",
    "    prompt = create_health_summary_advice_prompt(health_data) # Reuse the prompt creation function from the previous step\n",
    "\n",
    "    try:\n",
    "        # Send the prompt to the LLM\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "\n",
    "        # Return the generated text\n",
    "        return response.text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during LLM interaction: {e}\"\n",
    "\n",
    "# --- Example Usage (using data from the dataset) ---\n",
    "if df is not None and not df.empty and gemini_model is not None:\n",
    "    # Use data from the first individual in the dataset as an example\n",
    "    first_individual_data = df.iloc[0].drop('id').to_dict()\n",
    "    print(\"\\nGenerating health summary and advice for the first individual in the dataset...\")\n",
    "    health_summary_advice = get_health_summary_and_advice(first_individual_data)\n",
    "    print(\"\\n--- Health Summary and Advice ---\")\n",
    "    print(health_summary_advice)\n",
    "elif df is None or df.empty:\n",
    "    print(\"\\nDataFrame is not loaded or is empty. Cannot generate example summary and advice.\")\n",
    "elif gemini_model is None:\n",
    "     print(\"\\nGenerative Model is not initialized. Cannot generate example summary and advice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63981404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your health data:\n"
     ]
    }
   ],
   "source": [
    "def get_user_input_and_provide_advice():\n",
    "    \"\"\"\n",
    "    Prompts the user for health data, generates a summary and advice using the LLM,\n",
    "    and displays the results.\n",
    "    \"\"\"\n",
    "    user_health_data = {}\n",
    "\n",
    "    print(\"Please enter your health data:\")\n",
    "\n",
    "    try:\n",
    "        user_health_data['age'] = float(input(\"Age (in days): \"))\n",
    "        user_health_data['gender'] = float(input(\"Gender (1: female, 2: male): \"))\n",
    "        user_health_data['height'] = float(input(\"Height (in cm): \"))\n",
    "        user_health_data['weight'] = float(input(\"Weight (in kg): \"))\n",
    "        user_health_data['ap_hi'] = float(input(\"Systolic blood pressure (ap_hi): \"))\n",
    "        user_health_data['ap_lo'] = float(input(\"Diastolic blood pressure (ap_lo): \"))\n",
    "        user_health_data['cholesterol'] = float(input(\"Cholesterol (1: normal, 2: above normal, 3: well above normal): \"))\n",
    "        user_health_data['gluc'] = float(input(\"Glucose (1: normal, 2: above normal, 3: well above normal): \"))\n",
    "        user_health_data['smoke'] = float(input(\"Smoking (0: no, 1: yes): \"))\n",
    "        user_health_data['alco'] = float(input(\"Alcohol intake (0: no, 1: yes): \"))\n",
    "        user_health_data['active'] = float(input(\"Physical activity (0: no, 1: yes): \"))\n",
    "        user_health_data['cardio'] = float(input(\"Presence or absence of cardiovascular disease (0: no, 1: yes): \"))\n",
    "\n",
    "        print(\"\\nGenerating health summary and advice based on your input...\")\n",
    "        health_summary_advice = get_health_summary_and_advice(user_health_data)\n",
    "\n",
    "        print(\"\\n--- Your Health Summary and Advice ---\")\n",
    "        print(health_summary_advice)\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter numerical values where expected.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the function to test with user input\n",
    "if gemini_model is not None:\n",
    "    get_user_input_and_provide_advice()\n",
    "else:\n",
    "    print(\"\\nGenerative Model is not initialized. Cannot test with user input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de3b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf32a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Enhanced Summary with Personalized Suggestions ===\n",
      "\n",
      "You are a clinical AI assistant. Based on the patient details and risk predictions below, provide: A concise clinical summary of the patient's cardiovascular risk. At least three clear and actionable health suggestions tailored to the patient’s specific metrics, including diet, exercise, medication, and lifestyle changes.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c2435",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age_years'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m patient_data \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Feature engineering\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m features \u001b[38;5;241m=\u001b[39m engineer_features(patient_data\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m     19\u001b[0m input_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([features])\n\u001b[0;32m     20\u001b[0m input_df \u001b[38;5;241m=\u001b[39m input_df[expected_order]\n",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m, in \u001b[0;36mengineer_features\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mengineer_features\u001b[39m(data):\n\u001b[1;32m----> 2\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage_years\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage_years\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m365.25\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight_cm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_kg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age_years'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5989d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id;age;gender;height;weight;ap_hi;ap_lo;cholesterol;gluc;smoke;alco;active;cardio']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bbb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
